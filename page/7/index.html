
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Joseph Wilk</title>
  <meta name="author" content="Joseph Wilk">

  
  <meta name="description" content="A vector space search involves converting documents into vectors. Each dimension within the vectors represents a term. If a document contains that &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://josephwilk.github.io/page/7/index.html">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Joseph Wilk" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<script src="http://disqus.com/forums/josephwilk/embed.js"></script>
<link href="http://fonts.googleapis.com/css?family=Bevan" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-3020740-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <img src="/images/joe_small2.png" style="position:relative;border-radius: 8px;margin-right: 5px;border-style: solid;border-width: 1px;border-color: #DDD;" height="60" alt="Joseph Wilk">
  <span style="display:inline-block">
    <h1><a href="/">Joseph Wilk</a></h1>
    <h2>Things with code, creativity and computation.</h2>
  </span>
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="site:josephwilk.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
 <li><a href="/">Home</a></li>
 <li><a href="/about">About</a></li>
 <li><a href="/speaking">Speaking</a></li>
 <li><a href="/art">Art</a></li>
 <li><a href="/contact">Contact</a></li>
 <li><a href="/archives">Archives</a></li>
</ul>
</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/projects/building-a-vector-space-search-engine-in-python.html">Building a Vector Space Search Engine in Python</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-27T08:08:49+00:00" pubdate data-updated="true">Nov 27<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>A vector space search involves converting documents into vectors. Each dimension within the vectors represents a term. If a document contains that term then the value within the vector is greater than zero.</p>

<p>Here is an implementation of Vector space searching using python (2.4+).</p>

<h3>1 Stemming &amp; Stop words</h3>

<p>Fetch all terms within documents and clean &ndash; use a stemmer to reduce. A stemmer takes words and tries to reduce them to there base or root. Words which have a common stem often have similar meanings.
Example:
<em>CONNECTED
CONNECTING
CONNECTION
CONNECTIONS</em></p>

<p>all map to <em>CONNECT</em></p>

<p>We also remove any stopwords from the documents. [a,am,an,also,any,and] are all examples of stopwords in English.  Stop words have little value in search so we strip them. The stoplist used was taken from: <a href="ftp://ftp.cs.cornell.edu/pub/smart/english.stop">ftp://ftp.cs.cornell.edu/pub/smart/english.stop</a></p>

<pre><code> self.stemmer = PorterStemmer()
</code></pre>

<figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'>     <span class="k">def</span> <span class="nf">removeStopWords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="nb">list</span><span class="p">):</span>
</span><span class='line'>             <span class="sd">&quot;&quot;&quot; Remove common words which have no search value &quot;&quot;&quot;</span>
</span><span class='line'>             <span class="k">return</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">list</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stopwords</span> <span class="p">]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>     <span class="k">def</span> <span class="nf">tokenise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">string</span><span class="p">):</span>
</span><span class='line'>             <span class="sd">&quot;&quot;&quot; break string up into tokens and stem words &quot;&quot;&quot;</span>
</span><span class='line'>             <span class="n">string</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clean</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>
</span><span class='line'>             <span class="n">words</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot; &quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>             <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<h3>2 Map Keywords to Vector Dimensions</h3>

<p>Map the vector dimensions to keywords using a dictionary: keyword=>position</p>

<figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">getVectorKeywordIndex</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documentList</span><span class="p">):</span>
</span><span class='line'>        <span class="sd">&quot;&quot;&quot; create the keyword associated to the position of the elements within the document vectors &quot;&quot;&quot;</span>
</span><span class='line'>
</span><span class='line'>        <span class="c">#Mapped documents into a single word string</span>
</span><span class='line'>        <span class="n">vocabularyString</span> <span class="o">=</span> <span class="s">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">documentList</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">vocabularyList</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">tokenise</span><span class="p">(</span><span class="n">vocabularyString</span><span class="p">)</span>
</span><span class='line'>        <span class="c">#Remove common words which have no search value</span>
</span><span class='line'>        <span class="n">vocabularyList</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">removeStopWords</span><span class="p">(</span><span class="n">vocabularyList</span><span class="p">)</span>
</span><span class='line'>        <span class="n">uniqueVocabularyList</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">removeDuplicates</span><span class="p">(</span><span class="n">vocabularyList</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">vectorIndex</span><span class="o">=</span><span class="p">{}</span>
</span><span class='line'>        <span class="n">offset</span><span class="o">=</span><span class="mi">0</span>
</span><span class='line'>        <span class="c">#Associate a position with the keywords which maps to the dimension on the vector used to represent this word</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">uniqueVocabularyList</span><span class="p">:</span>
</span><span class='line'>                <span class="n">vectorIndex</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">=</span><span class="n">offset</span>
</span><span class='line'>                <span class="n">offset</span><span class="o">+=</span><span class="mi">1</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">vectorIndex</span>  <span class="c">#(keyword:position)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>3 Map Document Strings to Vectors.</h3>

<p>We use the simple Term Count Model. A more accurate model would be to use <a href="http://en.wikipedia.org/wiki/Tf-idf">tf-idf</a> (termFrequency-inverseDocumentFrequnecy).</p>

<figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">makeVector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wordString</span><span class="p">):</span>
</span><span class='line'>        <span class="sd">&quot;&quot;&quot; @pre: unique(vectorIndex) &quot;&quot;&quot;</span>
</span><span class='line'>
</span><span class='line'>        <span class="c">#Initialise vector with 0&#39;s</span>
</span><span class='line'>        <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorKeywordIndex</span><span class="p">)</span>
</span><span class='line'>        <span class="n">wordList</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">tokenise</span><span class="p">(</span><span class="n">wordString</span><span class="p">)</span>
</span><span class='line'>        <span class="n">wordList</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">removeStopWords</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">wordList</span><span class="p">:</span>
</span><span class='line'>                <span class="n">vector</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorKeywordIndex</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span> <span class="c">#Use simple Term Count Model</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">vector</span>
</span></code></pre></td></tr></table></div></figure>


<h3>4 Find Related Documents</h3>

<p>We now have the ability to find related documents. We can test if two documents are in the concept space by looking at the the cosine of the angle between the document vectors.  We use the cosine of the angle as a metric for comparison. If the cosine is 1 then the angle is 0° and hence the vectors are parallel (and the document terms are related).  If the cosine is 0 then the angle is 90° and the vectors are perpendicular (and the document terms are not related).</p>

<p>We calculate the cosine between the document vectors in python using scipy.</p>

<figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">cosine</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">):</span>
</span><span class='line'>        <span class="sd">&quot;&quot;&quot; related documents j and q are in the concept space by comparing the vectors :</span>
</span><span class='line'><span class="sd">                cosine  = ( V1 * V2 ) / ||V1|| x ||V2|| &quot;&quot;&quot;</span>
</span><span class='line'>        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span><span class="n">vector2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">vector1</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm</span><span class="p">(</span><span class="n">vector2</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<h3>5 Search the Vector Space!</h3>

<p>In order to perform a search across keywords we need to map the keywords to the vector space. We create a temporary document which represents the search terms and then we compare it against the document vectors using the same cosine measurement mentioned for relatedness.</p>

<figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">searchList</span><span class="p">):</span>
</span><span class='line'>        <span class="sd">&quot;&quot;&quot; search for documents that match based on a list of terms &quot;&quot;&quot;</span>
</span><span class='line'>        <span class="n">queryVector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buildQueryVector</span><span class="p">(</span><span class="n">searchList</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">ratings</span> <span class="o">=</span> <span class="p">[</span><span class="n">util</span><span class="o">.</span><span class="n">cosine</span><span class="p">(</span><span class="n">queryVector</span><span class="p">,</span> <span class="n">documentVector</span><span class="p">)</span> <span class="k">for</span> <span class="n">documentVector</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">documentVectors</span><span class="p">]</span>
</span><span class='line'>        <span class="n">ratings</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">ratings</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Further Extensions</h3>

<ol>
<li><p> Use tf-idf rather than the Term count model for term weightings</p></li>
<li><p> Instead of linear processing of all document vectors when searching for related content use:  <a href="http://en.wikipedia.org/wiki/Lanczos_method">Lanczos methods</a> OR a <a href="http://en.wikipedia.org/wiki/Neural_network">neural network</a>-like approach.</p></li>
<li><p> Moving towards <a href="http://en.wikipedia.org/wiki/Latent_semantic_indexing">Latent Semantic analysis</a>, <a href="http://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis">Probabilistic latent semantic analysis</a> or <a href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet allocation</a>.</p></li>
</ol>


<h3>Third Party tools</h3>

<p>The stemmer used comes from:
<a href="http://tartarus.org/~martin/PorterStemmer/python.txt">http://tartarus.org/~martin/PorterStemmer/python.txt</a></p>

<p>And the library for performing cosine calculations comes from NumPy:
<a href="http://www.scipy.org/">http://www.scipy.org/</a></p>

<h3>Source</h3>

<p><a href="https://github.com/josephwilk/semanticpy.git">https://github.com/josephwilk/semanticpy.git</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/projects/prolog-asldicn-event-calculus-planner.html">Prolog ASLDICN Event Calculus Planner</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-23T07:31:27+00:00" pubdate data-updated="true">Nov 23<span>rd</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The event calculus planner used within my thesis was based on Dr. Murray Shanahan&rsquo;s ASLDICN (Abductive SLD with Integrity constraints and proof by Negation) planner with compound action support. This planner is an adaptation from one published in one of Dr. Shanahan&rsquo;s research papers</p>

<p><a href="http://casbah.ee.ic.ac.uk/~mpsha/planners.html">http://casbah.ee.ic.ac.uk/%7Empsha/planners.html</a></p>

<p>The original planner only supports the generation of a single plan. I needed to support conditional planning. I wanted the planner to generate multiple plans representing the different ways of reaching the goal. The problem was how to convert the planner to generate all possible plans. Importantly ensuring that this does not cause infinite looping and no redundant plan solutions are generated.</p>

<p>My version of the planner add the following features:</p>

<ul>
<li><p>Conditional Planning</p></li>
<li><p>Impossible Predicate</p></li>
<li><p>Occured And NotOccured predicates</p></li>
</ul>


<h3>Prolog Event Calculus Planner</h3>

<p><a href="/workspace/prolog/eventCalculusPlanner.pl">Download eventCalculusPlanner.pl</a></p>

<p>[viewcode] src=../projects/prolog/eventCalculusPlanner.pl geshi=fortran[/viewcode]</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/projects/running-prolog-as-cgi.html">Running Prolog as CGI</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-23T07:27:25+00:00" pubdate data-updated="true">Nov 23<span>rd</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Prolog can be run as CGI by using a PHP wrapper script which invokes the Prolog engine from within PHP. Prolog can be invoked indicating Prolog files to load and goals to initially achieve once loaded.</p>

<p>Executing the following in PHP can spawn a process which runs Prolog.</p>

<pre><code>$cgiOutput = `sicstus --goal $goal. -l "$cgiPrologScriptToLoad"`;
</code></pre>

<p>This specific example is for Sicstus but most Prolog command lines have a similar format. Another possiblity is to setup Prolog as CGI, since any langauge can be CGI. I was running my code on a windows box and found it impossible for Prolog to direct the content to the command line and capture it for returning. If you&rsquo;re going the unix route you may want to look at <a href="http://clip.dia.fi.upm.es/Software/pillow/pillow.html">PiLLoWs</a> guide.</p>

<p>For form postings you can catch the post in PHP or a scripting language and create a prolog formated file which is passed to the prolog script when invoked.</p>

<p>You may want to have Prolog maintain state. This can be achieved through using a database. The database that I have used is <a href="http://www.sleepycat.com/">Berkeley DB</a> which SICStus has built in support for.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/projects/intelligent-workflow-management-system.html">Intelligent Workflow Management System</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-22T06:41:58+00:00" pubdate data-updated="true">Nov 22<span>nd</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Download PDF Thesis  <a href="http://www.doc.ic.ac.uk/teaching/projects/Distinguished04/JosephWilk.pdf">http://www.doc.ic.ac.uk/teaching/projects/Distinguished04/JosephWilk.pdf</a></p>

<p>This project took the HTML form systems as a model and built a Workflow Management System that uses artificial intelligence planning methodologies and Event Calculus workflow specifications to try to overcome some of the problems of Workflow Management Systems. Logic, server side languages and planning all rolled into one.</p>

<p><a href="/images/blog/2007/11/iwfms_screenshot.jpg"><img src="/images/blog/2007/11/iwfms_screenshot-1024x581.jpg" alt="" /></a></p>

<p>The development of the Workflow Management System with AI uncovered interesting issues in modelling situations in the Event Calculus and the
problems that need to be overcome to use AI with workflow. The problems and
solutions developed in the project cover a wide spectrum of domains, looking at logic
programming, server-side languages and getting the two to talk to each other. Areas
covered include such interesting topics as typing of HTML to new frameworks for
Prolog running as CGI.</p>

<h3>Achievements</h3>

<ul>
<li><p>Workflow specification language
Using the Event Calculus and extensions to specify workflow.</p></li>
<li><p>[HTML form typing | HTML typing in Prolog]
A typing engine for ensuring that the HTML form element specifications are
correct when used in workflow specifications.</p></li>
<li><p>A Visualisation tool for Event Calculus plans
A tool that generates Scalable Vector Graphic graphs for Event Calculus
plans.</p></li>
<li><p>A HTML/PHP iWFMS engine
Using the plans generated from the workflow specifications to support the
running and management of a system.</p></li>
<li><p>A JavaScript plan execution engine
Facilitates the following of workflow plans in a scripting language that runs
while the user is viewing and interacting with a web page.</p></li>
<li><p>Logic programming running as Common Gateway Interface (CGI)
A framework for the use of high-level declarative programming languages
functioning as CGI.</p></li>
<li><p>[Logic programming and server-side language interaction model | Interaction support between PHP and Prolog]
An Interaction model allowing server-side languages used for generating web
pages to interact with logic programming languages.</p></li>
<li><p>A Hospital model working example
An example of how the specification can be utilised for a real world scenario in
a hospital. Providing the full functionality within the iWFMS to run and manage
this system.</p></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/databases/pdo-zend-framework-playing-nicely-with-mssql.html">PDO & Zend Framework Playing Nicely With MSSQL</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-15T10:04:34+00:00" pubdate data-updated="true">Nov 15<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The task was to use the MSSQL database adapter (Zend_Db_Adapter_Pdo_Mssql) from the Zend-Framework and ensure it worked on both windows and Unix
platforms.</p>

<p>The PDO drivers were a little tricky. The main problem we found was that different drivers require the date to be inserted with different formats and the date that comes back from the db is in different formats.</p>

<p>Aside from having to deal with dates (which we handled as suggested by Bill Karwin) where we use Zend_Date and at the last point we convert it to a string date
<a href="http://framework.zend.com/issues/browse/ZF-181"> http://framework.zend.com/issues/browse/ZF-181</a></p>

<p>And Limit function not working:
<a href="http://framework.zend.com/issues/browse/ZF-1037"> http://framework.zend.com/issues/browse/ZF-1037</a></p>

<p>We have had no other problems connecting to MSSQL 2005 and MSSQL 2002 SQL Server.</p>

<p>The drivers we use are:
Windows
DB-LIB (MS SQL, Sybase) 5.1.6.6
<a href="http://pecl4win.php.net/"> http://pecl4win.php.net/</a></p>

<p>Unix
<a href="http://pecl.php.net/package/PDO_DBLIB"> http://pecl.php.net/package/PDO_DBLIB</a></p>

<p>Under Unix we use our own Zend_Db_Adapter_Pdo_Dblib which just extends Zend_Db_Adapter_Pdo_Mssql. We do this just to change the date format for insertion (we store the format required for a PDO adapter in each Zend_Db_Adapter_Pdo_* and use that when converting the date from a Zend_Date to a string).</p>

<p>As far as PHP/PDO is concerned &ndash;
Under Windows PHP runs pdo (mssql)
Under Unix PHP runs pdo (dblib)</p>

<p>I would be interested to hear what the performance is like using ODBC to talk to MSSQL Server. Looking at all the problems we had with dates and inconsistent drivers going the OBDC route does seem appealing just to get some consistency.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/projects/squid-and-members.html">Squid and Members</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-15T10:02:58+00:00" pubdate data-updated="true">Nov 15<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Task</h3>

<p>Use Squid to manage a cache for a website where there are member users (logged in to site) and public users. Squid must cache both member views of a page and public views.</p>

<p>Squid needs to check the authentication of the user and decided whether it should redirect them to a cache for members or for public users. There are only two discrete sets of users and any content that is specific to users if handled via AJAX.</p>

<ul>
<li><p>Squid will be operating as a transparent proxy.</p></li>
<li><p>Usernames/Passwords are stored within a MSSQL database.</p></li>
<li><p>Squid is hosted on a unix box along with Apache</p></li>
</ul>


<h3>Notes</h3>

<p>This project failed in its goal but why it failed was interesting! This initial solution came to a halt due to SQUID not providing the ability to filter return headers to clients browser. A application could have been written to do this, but this felt like the solution was becoming too complex with too many bottlenecks and dependencies</p>

<h3>SQUID &ndash; Authentication methods</h3>

<p>There are 3 different methods Squid provides for authentication:</p>

<ol>
<li><p> SAMBA &ndash; dealing with auth within a windows environment</p></li>
<li><p> SNMP &ndash; Simple Network Management protocol</p></li>
<li><p> Ident Protocol &ndash; Server Daemon on users computer</p></li>
</ol>


<p>SAMBA &ndash; No windows authentication mechanism within architecture</p>

<p>SNMP &ndash; ?</p>

<p>Ident Protocol &ndash; Requires demon on users computer. Impossible with a open web system</p>

<h3>Apache &ndash; Authentication through Proxy_Auth</h3>

<p>Three techniques for receiving user credentials.</p>

<ol>
<li><p> HTTP Basic protocol &ndash; Considered insecure</p></li>
<li><p> Digest authentication protocol &ndash;</p></li>
<li><p> NTLM &ndash; proprietary protocol developed by Microsoft</p></li>
</ol>


<p>So without a viable authentication method I decided to adopt a Kerbros like Authorisation Token. The cookie is created using AES.</p>

<p>The user has a secret key S known by themselves and the Web application.</p>

<pre><code>WebAppToken = Es{ TTL , emailaddress }
</code></pre>

<p>The email address is finally attached to the WebAppToken giving.</p>

<pre><code>email@test.co.uk:WebAppToken
</code></pre>

<p>The web application uses the email to identify the secret key of the user and tries to decrypt the token. The web application checks that the TTL has not expired.</p>

<p>Note this mechanism is susceptible to replay with the margin being that length to the TTL.</p>

<h3>Squid&rsquo;s ACL</h3>

<p>An external ACL script was used to allow access to the redirector. Hence access to this redirector implies that the user had valid permissions to be a member.</p>

<pre><code>external_acl_type type-name [options] format helper-command
</code></pre>

<h3>Squid Redirectors.</h3>

<ul>
<li><p>Squirm</p></li>
<li><p>External Script</p></li>
</ul>


<p>An external script was selected due to pressing time constraints. A simple python which changes URLS to be member urls. Any script running the redirector is assumed to be a member due to ACLs.</p>

<pre><code>/file/101010101010/filename.html
</code></pre>

<p>becomes</p>

<pre><code>/member/101010101010/filename.html
</code></pre>

<p>Apache has a mod-rewrite rule:</p>

<pre><code>RewriteRule ^/file/(.*)$ /file.php?controller=$1 
RewriteRule ^/member/(.*)$ /file.php?controller=$1member=true
</code></pre>

<h3>Architecture</h3>

<p><img src="http://joesniff.co.uk/spgm/gal/Diagrams/server_setup_squid_members.png" alt="" /></p>

<h3>Squid Config</h3>

<pre><code>external_acl_type WebAppTokenCheck ttl=1 concurrency=10 %{Cookie} /home/esw/squid/acl/WebAppACL.php 
acl MemberCookieCheck external WebAppTokenCheck 
#Only allow redirection on those pages that pass security test 
redirector_access deny all 
redirector_access allow MemberCookieCheck 

#Redirection 
redirect_program /home/esw/squid/redirectors/redirectors.py 
redirect_children 5
</code></pre>

<h3>Problems (sigh)</h3>

<ul>
<li><p>Client &ndash;> Squid request</p></li>
<li><p>Squid &ndash;> Apache</p></li>
<li><p>Apache &ndash;> Squid</p></li>
<li><p>Squid &ndash;> Client
The response from Apache must have the headers indicating cache settings. This is used by squid to identify how long and if it should cache response.</p></li>
</ul>


<p>These headers get returned to user client and there local browser detects the headers in the response and caches the file locally. Hence The client will not make another request to squid until the page is expired or a refresh is forced.</p>

<p>The client always needs to send its responses to squid as the state of the page is decided at squid (member/non-member).</p>

<p>It is possible to filter the response headers in Squid 3.0 via:</p>

<p>reply_header_access</p>

<p>Squid 2.5 is the current deployment version of Squid. So unless there is an alternative way to alter response headers need to move to Plan B.</p>

<h2>Links</h2>

<ul>
<li><p>Dos and Dont&rsquo;s of Web Authentication: <a href="http://cookies.lcs.mit.edu/pubs/webauth:tr.pdf">http://cookies.lcs.mit.edu/pubs/webauth:tr.pdf</a></p></li>
<li><p>mod_cache: <a href="http://httpd.apache.org/docs/2.0/mod/mod_cache.html">http://httpd.apache.org/docs/2.0/mod/mod_cache.html</a></p></li>
<li><p>Squid: <a href="http://www.squid-cache.org/">http://www.squid-cache.org/</a></p></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/critique/openid.html">OpenId</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-11T10:19:47+00:00" pubdate data-updated="true">Nov 11<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>OpenID is an open loosely distributed single sign on protocol. It looks at why Microsoft&rsquo;s single sign on has not taken off on a large scale. Concluding that no-one wants a single company storing all details, hence create a distributed single sign-on protocol.</p>

<p>OpenIDs take the form of URLS:</p>

<pre><code>exampleuser.livejournal.com
</code></pre>

<h3>OpenID 1.1 Protocol Summary</h3>

<p>OpenID specifications |<a href="http://openid.net/specs.bml">http://openid.net/specs.bml</a></p>

<p>The openid protocol 1.1 specification in summary.</p>

<ul>
<li><p>Identify the Identify Provider associated with openid submitted by the End User.</p></li>
<li><p>Agree a shared key between the Consumer and Identify Provider.</p></li>
<li><p>Redirect the End User to the Identify Provider to authenticate themselves with a password.</p></li>
<li><p>End User gets redirected back to Consumer with authentication data signed by the shared key.</p></li>
</ul>


<p>Dumb mode &ndash;> Consumer asks Identify Provider to return whether authentication data is valid.</p>

<p>Smart mode &ndash;> Consumer checks signed data with shared key</p>

<p>Diffie hellman <a href="http://en.wikipedia.org/wiki/Diffie-Hellman_key_exchange">http://en.wikipedia.org/wiki/Diffie-Hellman_key_exchange</a> can optionally be used when agreeing the shared key.</p>

<h3>Trust</h3>

<p>OpenID does not cover the concept of trust. Anyone could create a OpenID Identify Provider, create an id and then use this to login.</p>

<p>Hence its important to realise that the OpenID library implementations do not cover trust. A white list should be made which is then used to validate users Identify Providers and decide whether the consumer should trust them.</p>

<p>OpenID Provider Server URLs</p>

<ul>
<li><p>LiveJournal &ndash; <a href="http://www.livejournal.com/openid/server.bml">http://www.livejournal.com/openid/server.bml</a></p></li>
<li><p>Vox &ndash; <a href="http://www.vox.com/services/openid/server">http://www.vox.com/services/openid/server</a></p></li>
<li><p>VeriSign &ndash; <a href="https://pip.verisignlabs.com/server">https://pip.verisignlabs.com/server</a></p></li>
<li><p>MyOpenID &ndash; <a href="http://www.myopenid.com/server">http://www.myopenid.com/server</a></p></li>
</ul>


<p>There are other options than using white/black lists. Some of the more interesting ideas floating around about the use of Reputation.</p>

<p>Reputation for OpenID <a href="http://www.windley.com/archives/2007/03/reputation_for_openid.shtml">http://www.windley.com/archives/2007/03/reputation_for_openid.shtml</a></p>

<p>Wired &ndash; Herding the mob <a href="http://www.wired.com/wired/archive/15.03/herding.html">http://www.wired.com/wired/archive/15.03/herding.html</a></p>

<h3>Security Issues (On-going analysis)</h3>

<h4>Malicious End User &ndash; Denial Of Service</h4>

<p>A Malicious End User could have a OpenId which resolves to a malicious internal network. This internal connection could be for example: a [Tarpit|<a href="http://en.wikipedia.org/wiki/Tarpit_%28networking%29">http://en.wikipedia.org/wiki/Tarpit_%28networking%29</a>]. The Consumer is stuck in the tar pit, possibly timing out due to exceeding a maximum execution time.</p>

<p>Using a paranoid HTTP Library can help protect against this issue.</p>

<p><a href="http://search.cpan.org/~bradfitz/LWPx-ParanoidAgent-1.02/lib/LWPx/ParanoidAgent.pm">http://search.cpan.org/~bradfitz/LWPx-ParanoidAgent-1.02/lib/LWPx/ParanoidAgent.pm</a></p>

<h4>Secret keys passed plain text</h4>

<p>Its optional to pass the shared key using Diffie Hellman. Hence without Diffie Hellman the key could be sniffed passing between the Consumer and the Identity Provider.</p>

<h4>Replay attacks</h4>

<p>Nonces|<a href="http://en.wikipedia.org/wiki/Cryptographic_nonce">http://en.wikipedia.org/wiki/Cryptographic_nonce</a>] are not an integral part of the OpenID protocol.</p>

<p><em>&ldquo;OpenID Consumer&rsquo;s SHOULD add a self-signed nonce with Consumer-local timestamp in the openid.return_to URL parameters to prevent replay attacks. Details of that are left up to the Consumer.&rdquo;</em></p>

<p>Consumers can operate in dumb mode, meaning they store no state. Without storing state it is not possible to protect against replay attacks. The Consumer has no history of previous nonces. Hence it would not detect a old nonce used in a replay attack.</p>

<h4>Nonce Passing</h4>

<p>The nonce generated by the Consumer can cross the network 3 times in plaintext as GET parameters.</p>

<ul>
<li><p>Consumer Request to Identity Provider.</p></li>
<li><p>Identity Provider Redirection sent to End User (telling them to redirect to the Consumer)</p></li>
<li><p>End User request to Consumer.</p></li>
</ul>


<p>The greater the exposure of the nonce and the potential to sniff the shared key means a malicious attacker could create a fake/replay/pre-play response that the Consumer would accept.</p>

<h4>Delegating Authentication</h4>

<p>OpenID supports a URL delegating to a Identify Provider.
The URL delegates by providing &lsquo;links&rsquo; in the html at the URL location.</p>

<p>Example:</p>

<pre><code>&lt;link rel="openid.server" href="http://www.livejournal.com/openid/server.bml"&gt;




&lt;link rel="openid.delegate" href="http://exampleuser.livejournal.com/"&gt;
</code></pre>

<p>With a single point for delegation which is resolved without user interaction there is a risk that if this homepage is comprised the delegater could be changed to a malicious identify provider. This change could go un-noticed due to the automatic resolution.</p>

<p>This is a Trust issue and can be solved using whitelists and phishing protection at the Consumer.</p>

<h4>Phishing</h4>

<p>With the redirection from one login page to another there is a worry about phishing. How do you know you have not be redirected to some malicious signin page which steals you details rather than logging you in. URLs are an answer but a lot of people do not examine the URLS. This problem is not part of the OpenID protocol but rather a problem existing for all internet sites.</p>

<p>Verisign has a firefox plugin SeatBelt which attempts to detect if the OpenId site is legitimate.
SeatBelt|<a href="https://pip.verisignlabs.com/seatbelt.do">https://pip.verisignlabs.com/seatbelt.do</a></p>

<h4>Single Sign on &ndash; Break a single password = access to all accounts.</h4>

<p>A person on average has:
18 user accounts
3.47 passwords.</p>

<p>So people are using the same password for multiple accounts already. Single email accounts are tied to many user accounts. Any forgotten email reminders sent to an email address from a website mean the comprise of an email account can mean access to many other user accounts is possible.</p>

<p>Single sign-on is a risk and it would be safer to have separate user accounts each with different passwords. This however does not fit with how people are using the internet.</p>

<p>Its a comprise of convenience vs security and that decision needs to be made on a per solution basis.</p>

<h3>Security Summary</h3>

<p>The OpenID specification has optional features which if not used decrease the security of the system.</p>

<p>There are also security issues that are outside the OpenID protocol.</p>

<p>When using OpenID its important to access the security requirements of the problem and ensure that library implementations provide these optional features.</p>

<p>Different OpenID libraries implement the protocol and go beyond it dealing with issues like Nonces being passed in the clear to many times. Assess the libraries support of these issues.</p>

<p>Work outside of the OpenID is required to deal with the issue of Trust.</p>

<p>Phishing remains an issue.</p>

<h3>Openid Libraries</h3>

<p>The currently list of libraries implementations of OpenId are available in:</p>

<ul>
<li><p> C#</p></li>
<li><p> C++</p></li>
<li><p> Java</p></li>
<li><p> Perl</p></li>
<li><p> Python</p></li>
<li><p> Ruby</p></li>
<li><p> PHP</p></li>
<li><p> ColdFusion</p></li>
</ul>


<p>Many libraries go beyond the openid protocol and add protection against replay attacks.</p>

<h3>Yadis Protocol</h3>

<p>Although not part of the specification OpenID can use the [Yadis|<a href="http://yadis.org/wiki/Main_Page">http://yadis.org/wiki/Main_Page</a>] protocol:</p>

<p><em>The Yadis protocol enables discovery of service definitions from an <a href="http://">http://</a> or <a href="https://">https://</a> URL. The protocol consists of performing HTTP requests to obtain a Yadis Resource Descriptor.</em></p>

<p>This enables identify providers to be discovered through an OpenID. For our example OpenID we could look at the url:
exampleuser.livejournal.com</p>

<p><a href="http://exampleuser.livejournal.com">http://exampleuser.livejournal.com</a></p>

<h3>Links</h3>

<p><a href="http://openid.net/">http://openid.net/</a></p>

<p><a href="http://en.wikipedia.org/wiki/Diffie-Hellman_key_exchange">http://en.wikipedia.org/wiki/Diffie-Hellman_key_exchange</a></p>

<p><a href="https://pip.verisignlabs.com/seatbelt.do">https://pip.verisignlabs.com/seatbelt.do</a></p>

<p><a href="http://yadis.org/wiki/Main_Page">http://yadis.org/wiki/Main_Page</a></p>

<p><a href="http://en.wikipedia.org/wiki/Cryptographic_nonce">http://en.wikipedia.org/wiki/Cryptographic_nonce</a></p>

<p><a href="http://en.wikipedia.org/wiki/Tarpit_%28networking%29">http://en.wikipedia.org/wiki/Tarpit_%28networking%29</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/snippets/curl-and-certificates-with-windows-php.html">Curl and Certificates With Windows PHP</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-06T08:11:30+00:00" pubdate data-updated="true">Nov 6<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Curl on a Windows PHP installation does not know where to look for certificates. Hence when you try and curl a https url it fails. The default value for CURLOPT_SSL_VERIFYPEER is true which means curl will always try and validate ssl by default. I discovered this while working with an OpenID library (v1.2.3):
<a href="http://openidenabled.com/php-openid/">http://openidenabled.com/php-openid/</a></p>

<p>There is the option of disabling the verfication.</p>

<p><code>
$ch=curl_init;
// set URL and other appropriate options
curl_setopt($ch,CURLOPT_SSL_VERIFYPEER, false);
</code></p>

<p>But thats ignoring the problem and opening a security hole! Instead download a reputable Certificate bundle file, for example:
<a href="http://curl.haxx.se/docs/caextract.html">http://curl.haxx.se/docs/caextract.html</a></p>

<p>Then set CURLOPT_CAINFO with the location of your certificate bundle.</p>

<p><code>
if( strtoupper (substr(PHP_OS, 0,3)) == 'WIN' ) {
curl_setopt($c, CURLOPT_CAINFO, 'C:/certificates/cacert.pem');
}
</code></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/projects/automatic-tag-generation.html">Automatic Tag Generation</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-10-22T10:38:58+01:00" pubdate data-updated="true">Oct 22<span>nd</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This project looked at dynamically generating suggestion tags for content. To simplify the task some constraints where introduced.</p>

<ul>
<li><p>The content which will be tagged is news articles with HTML markup.</p></li>
<li><p>Only English content.</p></li>
</ul>


<p>I used the following HTML page to experiment on with suggestion tags: <a href="http://news.bbc.co.uk/1/hi/entertainment/6624223.stm">http://news.bbc.co.uk/1/hi/entertainment/6624223.stm
</a></p>

<p>To help evaluate the tagging methods I asked a sample of people to suggest what they thought the best tags would be. They came up with:</p>

<pre><code>paris, hilton, paris hilton, jail, jail sentence, drink-driving
</code></pre>

<h3>Whats a tag?</h3>

<p>Definition:
<em><strong>&ldquo;</strong>A tag is a (relevant) keyword or term associated with or assigned to a piece of information (e.g. a picture, a geographic map, a blog entry, or video clip), thus describing the item and enabling keyword-based classification and search of information.<strong>&rdquo;</strong></em></p>

<h3>Why tag?</h3>

<ul>
<li><p>Tag relevance draws on the wisdom of crowds</p></li>
<li><p>Tags create social awareness</p></li>
<li><p>Show Relevance and Popularity</p></li>
<li><p>Community contribution</p></li>
<li><p>Add searchable text for resources that cannot be accurately searched (videos, music, images, etc)</p></li>
</ul>


<h3>Examples of sites using tagging</h3>

<p><a href="http://www.last.fm/">http://www.last.fm/</a></p>

<p><a href="http://www.flickr.com/">http://www.flickr.com/</a></p>

<p><a href="http://www.youtube.com/">http://www.youtube.com</a></p>

<p><a href="http://del.icio.us/">http://del.icio.us/</a></p>

<h3>Tagging vocabulary</h3>

<p>The types of tagging vocabulary:</p>

<ul>
<li><p><strong>Factual</strong> &ndash; <em>Activism, Ajax, algorithms, animation, anime, art, audio, books, code, comics</em></p></li>
<li><p><strong>Subjective</strong> &ndash; <em>Great, good, great book, ok, good game, good read, great series, pretty good, wonderful</em>.</p></li>
<li><p><strong>Personal </strong>&ndash; <em>Seen at cinema, rented dvd, dave owns it</em></p></li>
</ul>


<h2>Proposed Solutions</h2>

<h3>Determining Semantic Information From the Grammatical Structure.</h3>

<p>I decided to use a Part of speech (Pos) Tagger to markup the grammar within the content. I discovered Pos Tagging through Satoshi Sekine Google tech talk presentation on <a href="http://video.google.com/videoplay?docid=369551663815274895&amp;q=type%3Agoogle+engEDU&amp;total=333&amp;start=30&amp;num=10&amp;so=1&amp;type=search&amp;plindex=2">On-Demand Information extraction</a> He suggests a new paradigm of Information Extraction which operates &lsquo;on demand&rsquo; in response to a user&rsquo;s query.</p>

<p>The Pos tagger selected was written in perl and while we are only looking at English it does support multiple languages.</p>

<p>TreeTagger: <a href="http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/">http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/</a></p>

<p>The Pos markup is based on:</p>

<p>Penn Treebank Tags: <a href="http://www.cis.upenn.edu/~treebank/home.html">http://www.cis.upenn.edu/~treebank/home.html</a></p>

<h4>Semantics from Grammar Experiments</h4>

<p>Experimentation rules:</p>

<ul>
<li><p>Extract all Proper Nouns</p></li>
<li><p>Where Proper Nouns are adjacent to each other combine to produce one Proper Noun</p></li>
<li><p>Order by frequency</p></li>
</ul>


<p>Results &ndash; (word, frequency):</p>

<pre><code>[ ('Hilton', 11),
('Paris-Hilton', 5),
('January', 3),
('June', 2),
('February', 2),
('Los-Angeles', 2),
('Howard-Weitzman', 1),
('Sunset-Boulevard', 1),
('paparazzi', 1),
('Paris-Hilton-Hilton', 1),
('Department', 1),
('Kathy', 1),
('Friday', 1),
('Los-Angeles-County-Sheriff', 1),
('Superior-Court', 1),
('Hilton-Hotel', 1),
('BBC', 1),
('David-Willis', 1),
('Metropolitan-Courthouse', 1),
('September', 1),
('California-Highway-Patrol', 1),
('Judge-Michael-Sauer', 1)]
</code></pre>

<p>We can see that by assuming a relationship between adjancent proper nouns we have produced some good tags
(Paris-Hilton, Los-Angeles-County-Sheriff) be it that they are long. Further feasibility of joining nouns needs to be performed to see if the cases where incorrect joins are made is worth the higher quaility tags. We also note that while the highest frequency results are good &lsquo;January&rsquo; and &lsquo;Feburary&rsquo; are weaker tags than some of the lower frequency tag.</p>

<h3>Name-entity Recognition</h3>

<p>Taggers which can use the concept of Hidden Markov Models <a href="http://en.wikipedia.org/wiki/Hidden_Markov_model">http://en.wikipedia.org/wiki/Hidden_Markov_model</a> (HMM).</p>

<p>Reform the problem to say that we have a document with names correctly marked up. This document is passed through a noisy channel which removes tags. The problem is to work out what the initial document was from the noisy data.</p>

<p>The HMM introduces a reduction in complexity as we only ever need to consider the previous state when evaluating whether a word is a name.</p>

<p>The Viterbi <a href="http://en.wikipedia.org/wiki/Viterbi_algorithm">http://en.wikipedia.org/wiki/Viterbi_algorithm</a> algorithm computes the most likely sequence of hidden states. Very good examples and python code in the wikipedia link.</p>

<p>The emission and transition probabilities need to be set from learning from a relevant corpus.</p>

<p>Application used (Java)</p>

<p>Named Entity Recognition (NER) and Information Extraction (IE)
<a href="http://nlp.stanford.edu/ner/index.shtml">http://nlp.stanford.edu/ner/index.shtml</a></p>

<p>Useful Links on Name Entity taggers:</p>

<p><a href="http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/">http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/</a></p>

<p>Impact of automatic comma prediction on pos/name tagging of speech
<a href="http://www.speech.sri.com/people/wwang/papers/slt06-comma-v11-newref.pdf">http://www.speech.sri.com/people/wwang/papers/slt06-comma-v11-newref.pdf</a></p>

<p>Nymble model
<a href="http://portal.acm.org/citation.cfm?doid=974557.974586">http://portal.acm.org/citation.cfm?doid=974557.974586</a></p>

<h4>Experimentation rules</h4>

<ul>
<li><p>Parse using Name Entity Tagger &ndash; identifying Person, Organisation and Location</p></li>
<li><p>reduce any adjoining Person/Organization/Location</p></li>
<li><p>Order by frequency</p>

<p>[ ((&lsquo;Ms-Hilton&rsquo;, &lsquo;PERSON&rsquo;), 10),
((&lsquo;Paris&rsquo;, &lsquo;LOCATION&rsquo;), 3),
((&lsquo;Los-Angeles&rsquo;, &lsquo;LOCATION&rsquo;), 3),
((&lsquo;Hilton&rsquo;, &lsquo;PERSON&rsquo;), 3),
((&lsquo;Paris-Hilton&rsquo;, &lsquo;LOCATION&rsquo;), 2),
((&lsquo;Hilton-Hilton&rsquo;, &lsquo;PERSON&rsquo;), 1),
((&lsquo;Department&rsquo;, &lsquo;ORGANIZATION&rsquo;), 1),
((&lsquo;Sunset-Boulevard&rsquo;, &lsquo;ORGANIZATION&rsquo;), 1),
((&lsquo;Judge-Michael-Sauer&rsquo;, &lsquo;PERSON&rsquo;), 1),
((&lsquo;California-Highway-Patrol&rsquo;, &lsquo;ORGANIZATION&rsquo;), 1),
((&lsquo;Kathy&rsquo;, &lsquo;PERSON&rsquo;), 1),
((&lsquo;BBC&rsquo;, &lsquo;ORGANIZATION&rsquo;), 1),
((&lsquo;Howard-Weitzman&rsquo;, &lsquo;PERSON&rsquo;), 1),
((&lsquo;Superior-Court&rsquo;, &lsquo;ORGANIZATION&rsquo;), 1),
((&lsquo;Metropolitan-Courthouse&rsquo;, &lsquo;ORGANIZATION&rsquo;), 1),
((&lsquo;Paris-Hilton&rsquo;, &lsquo;PERSON&rsquo;), 1),
((&lsquo;David-Willis&rsquo;, &lsquo;PERSON&rsquo;), 1)]</p></li>
</ul>


<p>Execution time: 5 seconds
Limiting the select to PERSON/ORGANIZATION/LOCATION helped removed some of the weaker tags suggested in the grammar experiment (like Feburary).</p>

<h3>Name-entity Recognition &ndash; Web</h3>

<p>A similar solution to the Name entity Tagger but rather than using the slower Java tool I used a free web based service. I found the web service produced similar results but considerable faster (around 1 second).
service:
<a href="http://tagthe.net/api/?url=http://news.bbc.co.uk/1/hi/entertainment/6624223.stm">http://tagthe.net/api/?url=http://news.bbc.co.uk/1/hi/entertainment/6624223.stm</a></p>

<p>[viewcode] src=../projects/xml/paris-tag-results.xml geshi=xml[/viewcode]</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/page/6/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
	  
      <li class="post">
        <a href="/art/audio-fingerprint-smudges.html">Audio Fingerprint Smudges</a>
      </li>
	  
    
      <li class="post">
        <a href="/art/overtone-shader-visuals.html">Visuals with Overtone and Shadertone</a>
      </li>
    
      <li class="post">
        <a href="/art/emacs-animation.html">Animations with Emacs</a>
      </li>
    
      <li class="post">
        <a href="/clojure/clojure-and-kinesis-at-scale.html">Clojure and Kinesis at scale</a>
      </li>
    
      <li class="post">
        <a href="/clojure/overtone-driving-minecraft.html">Clojure and Overtone driving Minecraft</a>
      </li>
    
      <li class="post">
        <a href="/art/live-coding-repl-electric.html">Live Coding - Repl Electric</a>
      </li>
    
      <li class="post">
        <a href="/clojure/creative_machines.html">Creative Machines</a>
      </li>
    
      <li class="post">
        <a href="/clojure/sounds-of-the-human-brain.html">Sounds of the human brain</a>
      </li>
    
      <li class="post">
        <a href="/clojure/building-clojure-services-at-scale.html">Building Clojure services at scale</a>
      </li>
    
      <li class="post">
        <a href="/clojure/creating-instruments-with-overtone.html">Creating sampled instruments with Overtone</a>
      </li>
    
      <li class="post">
        <a href="/elixir/sets-in-elixir.html">Sets in Elixir</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/josephwilk">@josephwilk</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'josephwilk',
            count: 10,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Joseph Wilk -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'josephwilk';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>





  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
