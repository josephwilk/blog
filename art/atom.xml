<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: art | Joseph Wilk]]></title>
  <link href="http://josephwilk.github.io//art/atom.xml" rel="self"/>
  <link href="http://josephwilk.github.io/"/>
  <updated>2016-01-08T15:34:16+00:00</updated>
  <id>http://josephwilk.github.io/</id>
  <author>
    <name><![CDATA[Joseph Wilk]]></name>
    <email><![CDATA[joe@josephwilk.net]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Visuals with Overtone and Shadertone]]></title>
    <link href="http://josephwilk.github.io/art/overtone-shader-visuals.html"/>
    <updated>2016-01-08T14:58:12+00:00</updated>
    <id>http://josephwilk.github.io/art/overtone-shader-visuals</id>
    <content type="html"><![CDATA[<p>Exploring techniques for creating live coded performances with Overtone and <a href="https://www.opengl.org/wiki/Fragment_Shader">OpenGL Fragment Shaders</a>. Much learnt from my work performing as <a href="https://vimeo.com/replelectric">Repl Electric</a>. All my shader source code for these performances is open: <a href="https://github.com/repl-electric/cassiopeia/tree/master/resources/shaders">https://github.com/repl-electric/cassiopeia/tree/master/resources/shaders</a></p>

<p><img src="http://josephwilk.github.io/images/end-of-buffer.png" alt="shaders"/></p>

<p>To bring OpenGl to Clojure I use <a href="https://github.com/overtone/shadertone">Shadertone</a> written by <a href="https://github.com/rogerallen">rogerallen</a>. This utilises LWJGL (Java Light Weight Java Game Library <a href="https://www.lwjgl.org">https://www.lwjgl.org</a>).</p>

<h3>The Bridge between Clojure and Shaders</h3>

<p>A vital feature of Shadertone is a map between Clojure atoms and shader Uniforms. What is a shader Uniform? Well think of it as a read-only global variable in your shader. A Clojure watcher ensures any updates to your Clojure atom persist into your Uniform. A little clunky but all uniforms start with the letter <code>i</code>.</p>

<p>The shader:
<code>c
uniform float iExample;
</code></p>

<p>And in Clojure</p>

<p>```clojure
(def example-weight (atom 0.5))
(shadertone/start-fullscreen &ldquo;resources/shaders/example.glsl&rdquo;
  :user-data {&ldquo;iExample&rdquo; example-weight})</p>

<p>;;iExample Uniform will also be updated.
(reset! example-weight 0.2)
```</p>

<h2>Live editing shaders</h2>

<p>When a shader file is edited Shadertone is watching the file (using <a href="https://github.com/ibdknox/watchtower">watchtower</a>) and will reload/recompile the changed file. This results in a slight freeze as the new code is run (This might be down to my graphics card).
Hence most of the time I prefer alternatives to live editing the shader to create smoother transitions.</p>

<h2>Injecting movement</h2>

<p>To make static images move we need a continuously changing value.</p>

<p>Shadertone gives us <code>iGlobalTime</code> using the number of seconds since the shader was started:</p>

<p>```c
uniform iGlobalTime</p>

<p>void main(void){
  //Use the continuously changing time signal as the value for a color.<br/>
  gl_FragColor = vec4(sin(iGlobalTime)*0.5+0.5);
}
```</p>

<p>Putting a continuously changing value through a function like sin/cos is the
bread and butter of creating animations with shaders.</p>

<h2>Randomness</h2>

<p>We often need a cheap and fast way to generate random floats in Shaders. Without persistent state and preservation of a seed it can be difficult. One solution is to use a noise image and the current pixel coordinates as an index into the image for a  float value.</p>

<p>Shadertone supports loading custom textures into your shaders:</p>

<p>```clojure
(shadetone/start &ldquo;shaders/example.glsl&rdquo;</p>

<pre><code>     :textures ["/josephwilk/textures/noise.png"])
</code></pre>

<p>```</p>

<p>The noise texture:</p>

<p><img src="http://raw.githubusercontent.com/josephwilk/shaderview/master/bin/data/textures/tex10.png" /></p>

<p>And finally the shader:</p>

<p><code>c
//Turning the current pixel coordinates (uv) into a random float.
vec2 uv = gl_FragCoord.xy / iResolution.xy;
return texture2D(iChannel0, vec2(uv)/256.0, 0.0);
</code></p>

<h2>Composing visual effects</h2>

<p>I attach a weight to each function or visual phase of the shader. Through this we can select which visual effect is visible or combine multiple effects. Its a bit messy, since I have all my functions in a single shader file. I&rsquo;ve not explored including of external files with shaders.</p>

<p>```c
uniform float iCircularWeight;
uniform float iPopulationWeight;</p>

<p>vec4 circular(){&hellip;}
vec4 population(){..}</p>

<p>void main(void){
  vec4 circleResult     = vec4(0.0);
  vec4 populationResult = vec4(0.0);
  if(iCircularWeight > 0.0){</p>

<pre><code>circleResult = circular() * iCircularWeight;
</code></pre>

<p>  }
  if(iPopulationWeight > 0.0){</p>

<pre><code>populationResult = population() * iPopulationWeight;
</code></pre>

<p>  }
  gl_FragColor = (populationResult + circleResult);
}
```</p>

<p>And within Clojure:</p>

<p>```clojure
(def circular-w (atom 1.0))
(def population-w (atom 1.0))
(shadertone/start-fullscreen &ldquo;resources/shaders/example.glsl&rdquo;
  :user-data {&ldquo;iCircularWeight&rdquo; circular-w</p>

<pre><code>          "iPopulationWeight" population-w})
</code></pre>

<p>(reset! circular-weight 1.0)
```</p>

<h2>Synchronisation</h2>

<p>Shadertone uses the seconds since start (<code>iGlobalTime</code>) while Overtone via Supercollider uses the soundcard&rsquo;s clock. Hence there is no guarantee these two sources will be in sync.</p>

<p>Replacing iGlobalTime is the only option. We create a special synth called <code>data-probes</code> which sole function is to transfer data from the Supercollider world to the Clojure world. Overtone provides a Supercollider to Clojure binding called a <code>tap</code>. We add a tap into our Overtone synth which is polling our global timing signal (this powers all synths and is how we co-ordinate everything).</p>

<p>```clojure
(defsynth data-probes [timing-signal-bus 0]
  (let [beat-count (in:kr timing-signal-bus)</p>

<pre><code>    _  (tap "global-beat-count" 60(a2k beat-count))
  (out 0 0))
</code></pre>

<p>(def active-data-probes (data-probes (:count time/beat-1th)))</p>

<p>(shadertone/start-fullscreen &ldquo;resources/shaders/example.glsl&rdquo;
  :user-data
  ;;An atom wrapping the tap and the running synth instance
   &ldquo;global-beat-count&rdquo; {&ldquo;iGlobalBeatCount&rdquo; (atom {:synth active-data-probes :tap &ldquo;global-beat-count&rdquo;})})
```</p>

<p>Using our <code>iGlobalBeatCount</code> in our shader now means anything requiring a continuously increasing value flows to our beat.</p>

<h2>Shaders &amp; global mutable state</h2>

<p>Persistent mutable state between executions is not possible in OpenGL Shaders. Uniforms are read-only.</p>

<p>Lets look at an example. On a drum hit I want the color of a visual to change and <em>persist</em> until the next drum hit.
The drum signal is 1 for a hit 0 for silence:</p>

<p><code>clojure
[1 0 0 0 1 0 0 0 1 0 0 0]
</code></p>

<p>The current value based on the global clock is passed into the Shader as the iBeat Uniform.</p>

<p>```c
uniform float iBeat;
float color = 0.0;</p>

<p>vec4 function showColor(){
  if(iBeat == 1.0){</p>

<pre><code>color += 1.0;
</code></pre>

<p>  }
  return vec4(color);
}
```</p>

<p>Will return:</p>

<p><code>c
vec4(1.0);
vec4(0.0);
vec4(0.0);
vec4(0.0);
vec4(1.0);
</code></p>

<p>What we were after is actually:</p>

<p><code>c
vec4(1.0);
vec4(1.0);
vec4(1.0);
vec4(1.0);
vec4(2.0);
</code></p>

<p>My solution is to move to Clojure where mutable state using atoms is simple.</p>

<p>Our timing is guided by Supercollider and a global clock. The value of our kick buffer at anyone time is only known inside the synth and hence inside Supercollider. But if we want to have mutable state we need access to this value in Clojure. So we create a custom synth that taps the value of the kick buffer based on the global clock signal.</p>

<p>```clojure
(defsynth drum-data-probe [kick-drum-buffer timing-signal-bus 0]
  (let [beat-count (in:kr timing-signal-bus)</p>

<pre><code>drum-beat (buf-rd:kr 1 kick-drum-buffer beat-count)
_  (tap "drum-beat" 60 (a2k drum-beat))])
</code></pre>

<p>  (out 0 0))</p>

<p>(defonce kick-drum-buffer (buffer 256))</p>

<p>;;Create the synth with the &ldquo;drum-beat&rdquo; tap
(def drum-data-probe (data-probes kick-drum-buffer (:count time/beat-1th)))</p>

<p>;;Bind the running synth and the tap
(def kick-atom (atom {:synth drum-data-probe :tap &ldquo;drum-beat&rdquo;}))</p>

<p>;;Extract the tap atom
(def kick-tap (get-in (:synth @kick-atom) [:taps (:tap @kick-atom)]))
```</p>

<p>Now in the Clojure world its simple to watch our tap atom and hence get alerted when it changes value. Overtone is dealing with the magic of updating the atom under the covers, the watcher is a nice implementation independent way of hooking into this. We now know the value of our kick buffer in Clojure. If we use another atom as our accumulator we can update it when the tap atom changes. Finally pushing this new accumulator to the Shader.</p>

<p>```clojure
(def active-color (atom 0.0))</p>

<p>(add-watch kick-tap :cell-color
  (fn [_ _ old new]</p>

<pre><code>(when (and (= old 0.0) (= 1.0 new))
(reset! active-color (mod (+ @active-color 1.0) 100)))))
</code></pre>

<p>```</p>

<p>Within the shader</p>

<p>```c
uniform float iActiveColor;</p>

<p>vec4 function showColor(){
  return vec4(iActiveColor);
}
```</p>

<p>Thats a lot of work, but I&rsquo;m very happy with the results in my <a href="https://vimeo.com/117516352">(end-of-buffer)</a> performance.</p>

<h2>Buffer events</h2>

<p>Writing to a buffer is a common way of live coding in Overtone. Its very useful to attach some visual effect based on the settings of a buffer.</p>

<p><code>clojure
;;Setting notes to a buffer
(def notes-buf (buffer 256))
(pattern! notes-buf (degrees-seq [:f3 1314]))
</code></p>

<p>We could put a tap into the synth and grab the current note and pass this into the shader. As I&rsquo;ve mentioned taps are expensive and they are always on while we may not always be using them.
This also gets more complicated when say we have 3 instances of the same synth running playing simultaneous to form a chord.</p>

<p>An alternative is to invent an atom which is used as a signal on every buffer write.</p>

<p><code>clojure
;;Could also do this with OSC messages...
(do
  (defonce buffer-change-event-notes-buf (atom 0.0))
  (pattern! notes-buf (degrees-seq [:f3 1314]))
  (swap! buffer-change-event-notes-buf + 1)
)
</code></p>

<p>And adding a watcher</p>

<p>```clojure
(add-watch
  buffer-change-event-notes-buf
  :buffer-change-event-notes-buf
  (fn [&amp; _]</p>

<pre><code>(let [n (int (buffer-get notes-buf 0))]
  (case n
    29 (reset! color 0.4)
       (reset! color 0.0)))))
</code></pre>

<p>(def buffer-atoms (atom {}))
(pattern! notes-buf)
(reset! buffer-atoms (assoc @buffer-atoms (:id notes-buf) (inc (@buffer-atoms (:id notes-buf)))))
```</p>

<p>I use this trick in (end-of-buffer) to use the bass note to control the level of distortion of the visuals (<a href="https://github.com/repl-electric/cassiopeia/blob/master/src/cassiopeia/destination/flatiron.clj#L84-L99">source</a>). Its wonderful to focus on the notes and feel the visuals following you automatically.</p>

<h2>Midi notes to visuals</h2>

<p>I often want to map a midi note to a visual effect. All my notes are mapped to buffers. Much like we did with the drums I can use a tap to get access to the current note being played in a buffer. Skipping over the details, when we have a midi note we send it as an float (to support crazy 42.333 like notes) to the shader via an atom.</p>

<p>We then map it to a nice range value to effect visuals:</p>

<p>```c
uniform float iLeadNote;</p>

<p>//midi note: 42 => F#2<br/>
//midi note: 78 => F#5
float noteMapped = smoothstep(42.0, 78.0, iLeadNote);</p>

<p>//noteMapped now spans => 0..1
```</p>

<p>A cheap way to scale effects based on the height of the note.</p>

<h2>Gradual transitions</h2>

<p>Often I want a smooth fading it or out of a shader function. Say for example fading to black. Pretty simple, just fire a thread which sleeps and ticks an atom. The atom is fed into the Shader.</p>

<p>```c
uniform float iColor;</p>

<p>void main(void){
  gl_color = vec4(iColor);
}
```</p>

<p>Since I use this a lot I created a helper fn in <a href="https://github.com/josephwilk/mud/blob/4866f9db8077f8d4244fdd94b42bc0fef0e69f40/src/mud/core.clj#L90">MUD</a>:</p>

<p><code>clojure
(def color (atom 1.0))
;;         atom / target /  rate
(overtime! color   0.0      0.001)
</code></p>

<h2>Text</h2>

<p>In end-of-buffer I spell the word Repl Electric out of floating lights. We are bound to only a few data structures with fragment Shaders. I used a simple 3x3 matrix mapping each part of a character. Then using this to decided the position of the lights.</p>

<p>```c
const mat3 LETTER_R        = mat3(1, 1, 1,</p>

<pre><code>                              1, 1, 0,  
                              1, 0, 1);
</code></pre>

<p>const mat3 LETTER_E        = mat3(1, 1, 1,</p>

<pre><code>                              1, 1, 0, 
                              1, 1, 1);
</code></pre>

<p>vec4 letter(mat3 letter, vec2 offset, vec2 uv){
  vec2 point = vec2(0,0);
  vec4 helloPoint = vec4(0,0,0,0);
  vec3 xPos = vec3(0.01, 0.03, 0.05);
  vec3 yPos = vec3(0.05, 0.03, 0.01);</p>

<p>  for(int y=0; y &lt; 3; y++){</p>

<pre><code>for(int x=0; x &lt; 3; x++){
  if(letter[y][x] == 1){// Show this part of the letter
    point = vec2(xPos[x]+offset.x, offset.y+yPos[y]);
    helloPoint += buildCell(uv, point, STATIC_LETTERS);
  }
}
</code></pre>

<p>  }
  return helloPoint;
}</p>

<p>letter(LETTER_R, 0.2, uv);                                                          <br/>
```</p>

<p>And the visual.</p>

<p><img src="http://josephwilk.github.io/images/font-example.png" alt="Font example"/></p>

<h2>Visuals effected by frequencies</h2>

<p>Shadertone provides a 2x512 array with the frequency spectrum (FFT) and audio waveform data. It does this by loading the data into a 2D Texture. The audio data is taken from tapping the main Overtone audio bus.</p>

<p><code>clojure
;;Tell Shadertone to fill iChannel0 with audio data
(shadetone/start "shaders/example.glsl" :textures [:overtone-audio])
</code></p>

<p>It&rsquo;s always a challenge to utilise this without creating something jerky or causing motion sickness. Hence I tend to use the waveform or FFT as a distorter rather than a base for animations.</p>

<p>It also helps to concentrate on specific ranges of frequencies of the waveform data to create a stronger connection between a synth and the visuals.</p>

<p>```
float sound = texture2D(iChannel0, vec2(max(uv.x,0.9),.75)).x;</p>

<p>//uv.xy => current x,y coordinates of pixel.</p>

<p>//First argument is an index into the 512 values of the waveform.
//By limiting the first argument we can ignore certain ranges.</p>

<p>//Second argument selects:
//    0.25 => FFT  <br/>
//    0.75 => audio waveform
```</p>

<p>Here is an example where I use the audio waveform to distort the scale &amp; jaggedness of a series of circle shapes.</p>

<p>```c
const float tau = 6.28318530717958647692;
vec3 wave = vec3(0.0);
float width = 4.0/500;
for (int i=0; i &lt; 60; i++){
  float sound = texture2D(iChannel0, vec2(uv.x,.75)).x;</p>

<p>  float a = 0.1<em>float(i)</em>tau/float(n);
  vec3 phase = smoothstep(-1.0,.5, vec3(cos(a), cos(a-tau/3.0), cos(a-tau<em>2.0/3.0)));
  wave += phase * smoothstep(width, 0.0, abs(uv.y &ndash; ((sound</em>0.9)+0.2)));</p>

<p>  //This shift of uv.x means our index into the sound data also moves along, examining a different part of the audio wave.
  uv.x += 0.4/float(n);
  uv.y &ndash;= 0.05;
}
wave *= 10.0/float(n);
return vec4(wave,1);
```</p>

<p>And the resulting visual:</p>

<p><img src="http://josephwilk.github.io/images/fft-example.png" alt="FFT example"/></p>

<h2>Final thoughts on Live coding visuals</h2>

<p>Through Clojure&rsquo;s binding of atoms with Fragment shaders we have the power to live code visuals and music. Though it comes at a cost of complexity having to wrap lots of functions in order to have powerfully connected visuals. Fragment shaders are extremely terse, and can be pushed to replicate many advanced effects <em>but</em> they are also performance intense, and often taking a non-shader route will be much more performant.</p>

<h4>Stability</h4>

<p>My knowledge of LWJGL is small, but crashes in the fragment shaders often occur leaving the JVM wedged. This has happened to me quite a lot practicing, but never in a performance. Its worth reflecting that something (be it fixable) leaves a risk of a freeze in a performance.</p>

<h4>Combining State &amp; Shaders</h4>

<p>I&rsquo;ve started to explore what a shader application might look like if it was a server and provided a state machine so the live coding language does have this complexity. In turn producing a freer and more spontaneous interaction. This project is <a href="https://github.com/josephwilk/shaderview">Shaderview</a> and steals all the good ideas of Shadertone while adding some new features like <a href="www.vertexshaderart.com">vertex shader art</a>. I&rsquo;ll be writing up more about Shaderview soon.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Animations with Emacs]]></title>
    <link href="http://josephwilk.github.io/art/emacs-animation.html"/>
    <updated>2015-10-02T15:58:12+01:00</updated>
    <id>http://josephwilk.github.io/art/emacs-animation</id>
    <content type="html"><![CDATA[<p>Emacs is designed for fast, highly customisable manipulation of text.
ASCII animation requires manipulating text at a sufficient speed that it appears animated. Emacs is also used by a number of performers to live code musical &amp; visual performances (and many other things). Where the audience can see the code in emacs and hear it.</p>

<p><img src="/images/live-coding-emacs.png" alt="Live Coding with Emacs" /></p>

<p>In my live coding performances as <a href="http://www.repl-electric.com">Repl Electric</a> I&rsquo;ve used emacs animations to  augment emacs with more feedback for the performer and a chance to destroy the order and structure the programmer has spent the entire performance building. Reminding us that we are looking at thoughts expressed through code that seem magical but are ultimately nothing more than text.</p>

<p>Maybe something akin to the creation and destruction of Sand Mandalas.</p>

<p><img src="/images/sandmandala.jpg" alt="Sand Mandala" /></p>

<h2>Framework for Emacs Animation</h2>

<p>Zone Mode is an Emacs plugin which provides a framework for screensaver like animations.</p>

<p><a href="http://www.emacswiki.org/emacs/ZoneMode">http://www.emacswiki.org/emacs/ZoneMode</a></p>

<p>Importantly it allows us to turn on an animation using our current code buffer as input and to terminate the animation, returning to the original code on a key press. So we can safely mangle the text knowing we can also return to safety. Well so far I&rsquo;ve always found it to be safe but there is a small risk as mentioned in the zoning warning:</p>

<p><code>lisp
(message "...here's hoping we didn't hose your buffer!")
</code></p>

<p>A nice property of taking our buffer as input is we are never quite sure what text will be there and hence the properties of the animation.</p>

<h3>Example: Uppercase all letters</h3>

<p>A simple function that finds non-whitespace in the buffer and tries to uppercase the char. It knows nothing about the zoning framework, its just a plain old function that operates on the active buffer.</p>

<p>```lisp
(defun zone-upper-case-text ()
  (zone-fill-out-screen (window-width) (window-height))
  (random t)
  (goto-char (point-min))
  (while (not (input-pending-p))</p>

<pre><code>(let ((wbeg (window-start))
      (wend (window-end)))

  ;;Keep moving the char cursor until its not whitespace
  (while (looking-at "[ \n\f]")
    (goto-char (+ wbeg (random (- wend wbeg))))))

;;If we are at the end of the buffer go to the last char
(when (eobp) (goto-char (point-min)))

;;Read the char at the cursor
(let ((c (char-after (point))))
  (delete-char 1)           ;; Remove the char
  (insert-char (upcase c))) ;; Reinsert with caps      

;;Sleep
(zone-park/sit-for (point-min) 0.1)))
</code></pre>

<p>```</p>

<p>The animation in all its glory:</p>

<iframe src="https://player.vimeo.com/video/141312958" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>


<h3>Zoning Setup</h3>

<p>We can override all other zoning programs and just specify our zone-fn. When we activate zoning our animation will be run.</p>

<p>```lisp
(eval-after-load &ldquo;zone&rdquo;
  &lsquo;(unless (memq 'zone-upper-case-text (append zone-programs nil))</p>

<pre><code>     (setq zone-programs [zone-upper-case-text])))
</code></pre>

<p>```</p>

<h3>Zoning Examples:</h3>

<p>Zoning mode comes with lots of example animations that are good starting points:</p>

<p><a href="http://www.opensource.apple.com/source/emacs/emacs-51/emacs/lisp/play/zone.el">http://www.opensource.apple.com/source/emacs/emacs-51/emacs/lisp/play/zone.el</a></p>

<ul>
<li>zone-pgm-jitter</li>
<li>zone-pgm-putz-with-case</li>
<li>zone-pgm-dissolve</li>
<li>zone-pgm-whack-chars</li>
<li>zone-pgm-rotate</li>
<li>zone-pgm-rotate-LR-lockstep</li>
<li>zone-pgm-rotate-RL-lockstep</li>
<li>zone-pgm-rotate-LR-variable</li>
<li>zone-pgm-rotate-RL-variable</li>
<li>zone-pgm-drip</li>
<li>zone-pgm-drip-fretfully</li>
<li>zone-pgm-five-oclock-swan-dive</li>
<li>zone-pgm-martini-swan-dive</li>
<li>zone-pgm-paragraph-spaz</li>
<li>zone-pgm-stress</li>
</ul>


<h2>Open Sound Control Protocol Based animation</h2>

<p>OSC is a handy protocol for sending data between networked devices using url like endpoints.
Emacs has a plugin to run an OSC server (<a href="http://delysid.org/emacs/osc.html">http://delysid.org/emacs/osc.html</a>).
Hence if we have some kind of beat signal we could send a message to Emacs and in turn it could render changes based on our musics timing.</p>

<p>With my Overtone setup for Repl-Electric I have the following flow of OSC messages:
<code>
[Supercollider] -&gt; OSC -&gt; [Clojure] -&gt; OSC -&gt; [Emacs]
</code></p>

<p>Within Emacs setup an OSC server and define two call backs which change the color of the window face number</p>

<p>```emacs-lisp
(require &lsquo;osc)
(require 'cl)</p>

<p>(defvar osc-server nil &ldquo;Connection to receive msgs&rdquo;)
(defvar flip-state t)</p>

<p>(defun osc-connect ()
  &ldquo;Create an OSC server and bind our fallback functions&rdquo;
  (when (not osc-server)</p>

<pre><code>(setq osc-server
      (osc-make-server
       "localhost" 4558
       (lambda (path &amp;rest args)
         (cond
          ((string-match "/beat" path)
           (progn (if flip-state (on-beat) (off-beat))
                  (setq flip-state (not flip-state))))))))))
</code></pre>

<p>(defun osc-make-server (host port default-handler)
  &ldquo;Settings for OSC server&rdquo;
  (make-network-process
   :name &ldquo;emacs OSC server&rdquo;
   :host host
   :server t
   :service port
   :filter #&lsquo;osc-filter
   :type 'datagram
   :family 'ipv4
   :plist (list :generic default-handler)))</p>

<p>(defun on-beat ()
  (custom-set-faces
   &lsquo;(window-number-face ((t (:foreground &ldquo;deeppink&rdquo;))))))</p>

<p>(defun off-beat ()
  (custom-set-faces
   &lsquo;(window-number-face ((t (:foreground &ldquo;#FDDD0C&rdquo;))))))</p>

<p>(osc-connect)
(provide &lsquo;osc-server)
```</p>

<p>In Overtone/Clojure the sending signal:</p>

<p><code>clojure
(defonce emacs-client (osc-client "localhost" 4558))
(def emacs-trigger    (on-beat-trigger 8 #(do (osc-send emacs-client "/beat"))))
</code></p>

<p>Heres a little demo with the brackets and window number changing colour based on the Overtone beat.</p>

<p><img src="/images/brackets.gif" alt="Emacs rendering to the beat" /></p>

<h3>Synchronisation</h3>

<p>Given some small local lag we now have a timing signal which is threaded through all our tools. <a href="http://supercollider.github.io/">Supercollider</a>, <a href="http://overtone.github.io/">Overtone</a> and Emacs.</p>

<p>Which means our emacs animations can start to change to the beat of the music&hellip;</p>

<h2>Sound in ASCII</h2>

<p>Now that we have ways to animate and to connect audio data with emacs we can go a little further (way too far) and start to visualise the data about our sound in ASCII.</p>

<p>From Overtone or SuperCollider we can create a synth which tracks the peak and power of an audio signal. It sends us messages back with the data which we then forward on as OSC messages to Emacs.</p>

<p>```c++</p>

<h1>Triggers a Sin Wave Oscillator and sends signals about power/peak</h1>

<p>SynthDef(\pulse,{</p>

<pre><code>var sig, chain, onsets;
sig = SinOsc.ar(Rand(220.0,440.0))
*EnvGen.ar(Env.perc(releaseTime:0.5),Dust.ar(0.5))*0.7;
Out.ar(0,sig !2);
//
chain = FFT({LocalBuf(512, 1)}, sig);
onsets = Onsets.kr(chain,0.1,\power);
SendTrig.kr(onsets);
SendPeakRMS.kr(sig, 20, 3, "/replyAddress");
</code></pre>

<p>}).add;</p>

<h1>Run the crazy synth above</h1>

<p>Synth(\pulse)</p>

<h1>Forward the data on as an OSC message</h1>

<h1>to emacs</h1>

<p>~host = NetAddr(&ldquo;localhost&rdquo;, 4859);
p = OSCFunc({ |msg|</p>

<pre><code>~host.sendMsg("/peakpower",msg[3], msg[4]);
"peak: %, rms: %".format(msg[3], msg[4]).postln
</code></pre>

<p>}, &lsquo;/replyAddress&rsquo;);
```</p>

<p>And in our emacs OSC server:</p>

<p>```emacs-lisp
((string-match &ldquo;/peakpower&rdquo; path)
  (progn</p>

<pre><code>(with-current-buffer "flatiron.clj"
  (let ((sig (round (* 100.0 (first args)))))
    (message (format "%f" (first args)))
    (dotimes (n sig)
      (insert "▓"))
    (insert "▒░"))
  (insert "\n"))))
</code></pre>

<p>```</p>

<iframe src="https://player.vimeo.com/video/141159277" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>


<h2>Repl Electric Emacs animations</h2>

<p>All my Emacs animations are used to conclude the performance.
Heres lies the source code, some screenshots and tricks &amp; tips that made the animations possible.</p>

<p>Here&rsquo;s a demo of all the Repl Electric animations discussed in action:</p>

<iframe src="https://player.vimeo.com/video/141310772" width="500" height="375" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>


<h3>End of Buffer</h3>

<p><a href="https://github.com/repl-electric/view-pane/blob/master/animations/end-of-buffer.el">https://github.com/repl-electric/view-pane/blob/master/animations/end-of-buffer.el</a></p>

<p><img src="http://josephwilk.github.io/images/endofbuffer01.png"/ alt="end-of-buffer-01"><img src="http://josephwilk.github.io/images/endofbuffer02.png" alt="end-of-buffer-02"/><img src="http://josephwilk.github.io/images/endofbuffer03.png" alt="end-of-buffer-03"/></p>

<p>In this animations the text gets slowly broken up with white spaces and then like the wind, blows the characters away. Sometimes words are ripped apart as they blow in the wind (if we get lucky).</p>

<p>Two main phases:</p>

<ul>
<li><p>Injection of spaces.
This starts to distort the text while keeping it readable. It provides a way to increase the effect of expanding whitespace in the next stage.</p></li>
<li><p>Transforming whitespace into lots of whitespace.
A Regex matches whitespace and replaces it with a randomly increasing amount of whitespace. Which leads to the effect of the characters of the code blowing away. I spent a while trying to improve the speed of this phase and Regexs proved to be the fastest way.</p></li>
</ul>


<p>If we move the text fast enough soft word wrapping means the text appears to re-enter from the left side of the screen and eventually disappear out of the buffer. Without soft wrapping we get a horrible jitter as emacs moves back and forth between left and right side of the buffer.</p>

<p>A couple of other tricks/tactics used:</p>

<ul>
<li>Continually incrementing integer. Useful for injecting movement or using sin/cos fn with a continuous value.</li>
<li>Perserving the syntax highlighting of the original code in an attempt to maintain some of the meaning of the code.</li>
</ul>


<h3>The Stars</h3>

<p><a href="https://github.com/repl-electric/view-pane/blob/master/animations/the-stars.el">https://github.com/repl-electric/view-pane/blob/master/animations/the-stars.el</a></p>

<p><img src="http://josephwilk.github.io/images/thestars01.png"/></p>

<p>This was my first animation and was based heavily on <code>zone-pgm-drip-fretfully</code>.</p>

<p>It randomly picks a single character and moves it down the screen until it hits another letter or exits the screen.</p>

<p>When running Emacs + Overtone + OpenGL, Emacs starts to slow down so part of the challenge was ensuring the animation ran as fast as possible.</p>

<p>A nice property of this is that as the OpenGL shaders shutdown, the speed of the animation increases and the code destroys itself more quickly.</p>

<h3>Waves</h3>

<p><a href="https://github.com/repl-electric/view-pane/blob/master/animations/waves.el">https://github.com/repl-electric/view-pane/blob/master/animations/waves.el</a></p>

<p><img src="http://josephwilk.github.io/images/waves01.png"/><img src="http://josephwilk.github.io/images/waves02.png"/></p>

<p>This animations attempts to simulate the effect of waves using line wrapping and mixing deletions with insertions of different sizes to create lines that seem to move at different speeds.</p>

<h2>Breaking Tools</h2>

<p>While it may seem silly to bend Emacs to do things it was never intended to do, it&rsquo;s an important part of discovering for yourself how you want your tools to work. Not just doing what you are expected but breaking them apart and discovering for yourself how you want to use them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Live Coding - Repl Electric]]></title>
    <link href="http://josephwilk.github.io/art/live-coding-repl-electric.html"/>
    <updated>2014-06-13T15:58:12+01:00</updated>
    <id>http://josephwilk.github.io/art/live-coding-repl-electric</id>
    <content type="html"><![CDATA[<p>Live coding is the act of turning a programming session into a performance. This can constitute improvisation, music, visuals, poetry, hardware, robots, dance, textiles and people. Pretty much anything with an input and output can be controlled live by programming.</p>

<p>This is not just a performance by programmers for programmers. While this is often where it starts as a live coder, the type of audience and the accessibility of the performance lies in the performers imagination. Abstraction can get us pretty much anywhere.</p>

<p><code>clojure
(def the-stars (dark-matter))
</code></p>

<h2>Repl Electric</h2>

<p><img src="https://camo.githubusercontent.com/d1711cc92a1b79af187344f461be35e2ced44e3f/687474703a2f2f7333302e706f7374696d672e6f72672f7633336377783668642f53637265656e5f53686f745f323031345f30345f32385f61745f32305f31345f33352e706e67"/></p>

<p><a href="http://www.repl-electric.com">Repl Electric</a> is a project I started in order to discover more about music composition and Artificial intelligent based aids to creativity. Which in turn through the inspiration of people like <a href="http://meta-ex.com/">Meta-ex</a> lead me to live programming music.</p>

<p>Here is a performance live coding music and graphics, inspired by a performance in London:</p>

<h3>The Stars</h3>

<iframe src="http://josephwilk.github.io//player.vimeo.com/video/95988263" width="500" height="313" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>


<h3>Open Live Coding</h3>

<p>All the tools and code used to create this performance are open for all to see on Github: <a href="https://github.com/repl-electric">https://github.com/repl-electric</a></p>

<p>Three programming languages were used to create this piece:</p>

<ul>
<li>Clojure (Sound)</li>
<li>GLSL (Visuals)</li>
<li>Emacs Lisp (Animations &amp; Navigation)</li>
</ul>


<h3>Tools</h3>

<p>Here are the tools used and a little detail around how they where used in performing &ldquo;The Stars&rdquo;:</p>

<h4>Clojure: <a href="http://clojure.org">http://clojure.org</a></h4>

<p>Clojure is a LISP language based on the JVM.</p>

<p>Clojure focuses on interactive REPL (Read, Evaluate, Print &amp; Loop) driven development. Which makes it a good choice for interactively coding music. It also turns out functional programming is a good fit for operating over music as data.</p>

<h4>Emacs Live: <a href="https://github.com/overtone/emacs-live">https://github.com/overtone/emacs-live</a></h4>

<p>Emacs live is a Emacs release with packages and defaults that are Live Coding centric. Something I use for both for my work and for my live coding.</p>

<p>To execute our code, we launch a repl instance in our project (NEVER launch inside emacs, since then if emacs crashes the repl and music dies) and connect to it from emacs using <code>cider</code> <a href="https://github.com/clojure-emacs/cider.">https://github.com/clojure-emacs/cider.</a></p>

<p>A simple trick to combine Emacs code and visualizations is to launch an OpenGL window in full screen (see Shadertone) and then put a full screen transparent terminal window running emacs over it.</p>

<p><img src="/images/terminal.png" alt="" /></p>

<p>The tumbling text effect seen at the end of the performance is an emacs animation using <code>Zone Mode</code> which supports writing your own text destructors: <a href="http://www.emacswiki.org/emacs/ZoneMode">http://www.emacswiki.org/emacs/ZoneMode</a></p>

<h4>Overtone: <a href="https://github.com/overtone/overtone">https://github.com/overtone/overtone</a></h4>

<p>Overtone is a Clojure based client to <a href="http://supercollider.sourceforge.net">SuperCollider</a>. Supercollider is an environment for real time audio synthesis and algorithmic composition.</p>

<p>Overtone provides us with:</p>

<ul>
<li>Timing (beat generation &ndash; <a href="https://github.com/repl-electric/cassiopeia/blob/master/src/cassiopeia/engine/timing.clj">example timing code</a>).</li>
<li>Building Synths (engineer sound).</li>
<li>Running samples (both your own and from <a href="https://www.freesound.org/">Freesound</a>).</li>
<li>Live Synth control (changing notes, durations, reverb, etc).</li>
<li>Hardware interaction (through midi or OSC).</li>
</ul>


<p>An example of a synth used in The Stars:</p>

<p>```clojure
(use &lsquo;overtone.live)
(defsynth dark-ambience [out-bus 0 amp 1 mul 0.2 room-size 70 rev-time 99 freq 60 ring-mul 55]
  (let [pink (hpf:ar (<em> (</em> 0.005 (pink-noise)) (line:kr 0 1 9)) 5)</p>

<pre><code>    src1 (ringz (* pink (lf-noise1:kr 0.15)) (+ freq (* ring-mul 0)) mul)
    src2 (ringz (* pink (lf-noise1:kr 0.15)) (+ freq (* ring-mul 1)) mul)
    src3 (ringz (* pink (lf-noise1:kr 0.15)) (+ freq (* ring-mul 2)) mul)
    src (tanh (g-verb (sum [src1 src2 src3]) room-size rev-time))]
(out out-bus (* amp src))))
</code></pre>

<p>(def the-stars (dark-ambience))
```</p>

<h6>Timing</h6>

<p>Timing is a complicated issue but so important its worth touching on. You have a choice with Overtone to use Java for timing or Supercollider. I use Supercollider since I have found it to be much more reliable.
Everything you need is here (<a href="https://github.com/repl-electric/cassiopeia/blob/master/src/cassiopeia/engine/timing.clj">copy and paste</a>), thanks to the hard work of <a href="https://github.com/samaaron">Sam Aaron</a>.</p>

<p>The key concept to take away is there are two types of timing, a beat counter which is forever incrementing and a beat trigger which flips back and forth between 1/0.</p>

<p>```clojure
(require &lsquo;[cassiopeia.engine.timing :as time])</p>

<p>;;The beat trigger
(:beat time/main-beat) ;=> 0,1,0,1,0,1,0</p>

<p>;;The beat counter
(:count time/main-beat) ;=> 0,1,2,3,4,5,6,7,8,9
```</p>

<p>The counter is useful for indexing buffers, the trigger is useful in controlling the gate of an envelope (which turns a sound on or off).</p>

<p>In Clojure we can still get access to the beat, in our timing code we send a message using <code>send-trig</code> on every beat. We can hook a Clojure function to callback on this beat:</p>

<p>```
(on-trigger (:trig-id time/main-beat)
  (fn [beat-no]</p>

<pre><code>(when (= 0.0 (mod beat-no 32))
  ;;play a sample
  (boom-s)))
</code></pre>

<p>  ::on-beat-trigger)
```</p>

<p>I use this extensively to time graphic transitions with the music.</p>

<h6>Buffers</h6>

<p>Most of my live coding performance was writing to buffers which are hooked into synths. Buffers are just fixed size arrays but they are stored in Supercollider rather than in Clojure. Here is an example from The Stars where the midi notes are read from a buffer at a rate based on my beat timing signal (a 16th of the main beat here).</p>

<p>```clojure
(use &lsquo;overtone.live)
(use 'cassiopeia.engine.core)
(require &rsquo;[cassiopeia.engine.timing :as time])</p>

<p>(defsynth growl [out-bus 0 note-buf 0 beat-bus 0 beat-trg-bus 0 amp 1]
  (let [cnt (in:kr beat-bus)</p>

<pre><code>    trg (in:kr beat-trg-bus)
    note (buf-rd:kr 1 note-buf cnt)
    freq (midicps note)
    vol (&gt; note 0)

    e (env-gen (perc :attack 10 :sustain 1 :release 1) :gate trg)
    src (lpf (mix [(saw (* 0.25 freq))
                   (sin-osc (* 1.01 freq))]))
    src (pitch-shift src 0.4 1 0 0.01)
    src (pan2:ar (* vol amp e src))]
(out out-bus src)))
</code></pre>

<p>(defonce nebular (buffer 96))</p>

<p>(def nebula (growl :note-buf nebula-note-buf :beat-trg-bus (:beat time/beat-16th) :beat-bus (:count time/beat-16th)))</p>

<p>(pattern! nebula-note-buf (degrees [1 3 7] :major :A2))
```</p>

<h4>GLSL + Shadertone:  <a href="https://github.com/overtone/shadertone">https://github.com/overtone/shadertone</a></h4>

<p>Shaders generate imagery directly on your Graphics Processing Unit rather than going through your CPU. Through a language called GLSL (which is C like) we can express very simple functions which get called on every single pixel generating complex visuals. Here is a simple extract from The Stars that generates all the background small dots:</p>

<p><img src="/images/glsl-dots.png" alt="" /></p>

<p>```glsl
void main(void){
  vec2 current_pixel_position = mod(gl_FragCoord.xy, vec2(5.0)) &ndash; vec2(0.0);
  float distance_squared = dot(current_pixel_position, current_pixel_position);</p>

<p>  vec4 black = vec4(.0, .0, .0, 0.0);
  vec4 white = vec4(1.0, 1.0, 1.0, 1.0);</p>

<p>  //Test the current pixel position and if it should be a circle shade it.
  vec4 circles = (distance_squared &lt; 0.6) ? white : black;</p>

<p>  gl_FragColor = circles;
}
```</p>

<p>For more examples of whats possible with Shaders checkout <a href="https://www.shadertoy.com">Shader Toy</a></p>

<p>Shadertone is the Clojure library that provides a convenient way of running shaders from Clojure and for feeding in data about our synths. It provides access in your Shader to:</p>

<ul>
<li>Overtone&rsquo;s Volume (<code>iOvertoneVolume</code>)</li>
<li>The frequency spectrum &amp; audio waveform data (Passed as a 2D texture <code>:textures [:overtone-audio]</code>)</li>
</ul>


<p>To synchronize the graphics with the music I created a special Overtone synth which does not generate any sound, it instead feeds information in realtime to my shader.</p>

<p>```clojure
(use &lsquo;overtone.live)
(require &rsquo;[shadertone.core :as t])</p>

<p>;;A synth that exposes through taps all the lovely timing information.
(defsynth buffer->tap [beat-buf 0 beat-bus 0 beat-size 16 measure 6]
  (let [cnt (in:kr beat-bus)</p>

<pre><code>    beat (buf-rd:kr 1 beat-buf cnt)
    _  (tap "beat"          60 (a2k beat))
    _  (tap "beat-count"    60 (a2k (mod cnt beat-size)))
    _  (tap "measure-count" 60 (a2k (/ (mod cnt (* measure beat-size)) measure)))])
</code></pre>

<p>  (out 0 0))</p>

<p>;;; Used to store our drum beat, 1 for a hit 0 and for a miss
(defonce drum-sequence-buffer (buffer 256))</p>

<p>(def beats (buffer->tap drum-sequence-buffer (:count timing/main-beat)))</p>

<p>;;Open a OpenGL window running our shader
(t/start-fullscreen &ldquo;resources/shaders/electric.glsl&rdquo;</p>

<pre><code>                :user-data {
                "iBeat"         (atom {:synth beats :tap "beat"})
                "iBeatCount"    (atom {:synth beats :tap "beat-count"})
                "iMeasureCount" (atom {:synth beats :tap "measure-count"})})
</code></pre>

<p>```</p>

<p>Inside our shader code:</p>

<p><code>glsl
uniform float iBeat;
uniform float iBeatCount;
uniform float iMeasureCount;
...
</code></p>

<p>The other main way of controlling a shader from Clojure is using <code>atoms</code>.</p>

<p>```clojure
(require &lsquo;[shadertone.core :as t])</p>

<p>(defonce cellular-growth (atom 0.0))</p>

<p>(t/start-fullscreen &ldquo;resources/shaders/electric.glsl&rdquo; :user-data {&ldquo;iCellularGrowth&rdquo; cellular-growth})</p>

<p>(swap! cellular-growth + 0.01)
```</p>

<h4>Hardware: Monome: <a href="http://monome.org">http://monome.org</a></h4>

<p>Something you don&rsquo;t see in the video is that I&rsquo;m using a 8x16 <a href="http://monome.org">Monome</a>. For this performance its primary function was a visual aid to show the beat/measure information.</p>

<p><img src="/images/monome.jpg" alt="Monome" /></p>

<p>The hardware is driven by Clojure communicating with the Monome through a serial port: <a href="https://github.com/josephwilk/monome-serial/tree/protocols">https://github.com/josephwilk/monome-serial/tree/protocols</a></p>

<h1>Live Coding</h1>

<p>Live coding music and graphics combines skills in sound engineering, 3d graphics, geometry, physics, musical theory, composition, improvisation &amp; hardware to name a few.</p>

<p>It is difficult, and requires a lot of work and practice.</p>

<p>But of all the code I&rsquo;ve written over the years this is one of the things I&rsquo;m most proud of. And i&rsquo;m only at the beginning of discovering what&rsquo;s possible.</p>
]]></content>
  </entry>
  
</feed>
